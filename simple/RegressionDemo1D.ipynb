{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n_samples=100, func=lambda x: np.cos(2 * np.pi * x), xlim=(-1, 1)):\n",
    "    np.random.seed(42)\n",
    "    x = np.random.uniform(*xlim, n_samples)\n",
    "    y = func(x)\n",
    "    return x[...,np.newaxis], y[...,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "#func = lambda x: -.6*x+(1 - (-.5 < x) * (x < -.08)) * np.cos(4 * np.pi * x / (.8 * x ** 2 + .7)) * np.exp(-x ** 2 + .3*x)\n",
    "func = lambda x: np.exp(-5*x**2)+ .4*np.exp(-10*(x-1.8)**2)\n",
    "\n",
    "func = lambda x: np.cos(10*x)/(1+np.abs(x))\n",
    "\n",
    "X0, Y0 = generate_samples(n_samples, func, xlim=(-1,1))\n",
    "\n",
    "\n",
    "X, X_val, Y, Y_val =  train_test_split(X0,Y0,train_size = 0.8)\n",
    "\n",
    "print(X.shape, Y.shape, X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "x = np.linspace(-2,2,200)\n",
    "plt.plot(x, func(x), color = \"k\", label = \"func\")\n",
    "plt.plot(X[:,0],Y[:,0],\"o\", color = \"C0\", label = \"train\")\n",
    "plt.plot(X_val[:,0],Y_val[:,0],\".\", color = \"C1\", label = \"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(activation = \"relu\", n_neurons=32, n_hidden = 2):\n",
    "    np.random.seed(42)\n",
    "    inp = Input((1,), name = \"input\")\n",
    "    layer = inp \n",
    "    for n in range(n_hidden):\n",
    "        layer = Dense(n_neurons,activation=activation, name= \"hidden_%s\"%(n+1))(layer)\n",
    "        \n",
    "    out = Dense(1, activation=None, name =  \"output\")(layer)\n",
    "    return Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def __init__(self, X, Y, xlim_test =(-1.5,1.5), n_interval = 5, smooth = .4, yscale = \"log\"):\n",
    "        self._n_interval = n_interval\n",
    "        self._logs = defaultdict(list)\n",
    "        self._logs_smooth = defaultdict(list)\n",
    "        self._weights = []\n",
    "        self._X_test = np.linspace(*xlim_test,200).reshape(-1,1)\n",
    "        self._X_train = X\n",
    "        self._Y_train = Y\n",
    "        self._axs = None\n",
    "        self._yscale = yscale\n",
    "        self._smooth = smooth\n",
    "        super(MyCallback,self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        for k,v in logs.items():\n",
    "            self._logs[k].append(v)\n",
    "            if epoch==0:\n",
    "                self._logs_smooth[k].append(v)\n",
    "            else:\n",
    "                self._logs_smooth[k].append((1-self._smooth)*v+self._smooth*self._logs_smooth[k][-1])\n",
    "            \n",
    "            \n",
    "        ws = np.concatenate([w.flatten() for w in self.model.get_weights()])\n",
    "        self._weights.append(ws)\n",
    "\n",
    "        Y_pred_test  = self.model.predict(self._X_test)\n",
    "        Y_pred_train = self.model.predict(self._X_train)\n",
    "\n",
    "        # plot every self._n_interval epoch \n",
    "        if (epoch % self._n_interval) ==0:\n",
    "\n",
    "            _, self.axs = plt.subplots(1, 2, figsize=(12,4))\n",
    "            self.axs = self.axs.flatten()    \n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            for i,k in enumerate(self._logs.keys()):\n",
    "                self.axs[0].plot(np.arange(epoch+1),self._logs[k], color = \"C%s\"%i, alpha = .2)\n",
    "                self.axs[0].plot(np.arange(epoch+1),self._logs_smooth[k], color = \"C%s\"%i,label = k)\n",
    "                \n",
    "            self.axs[0].legend()\n",
    "            self.axs[0].set_yscale(self._yscale)\n",
    "            \n",
    "            self.axs[1].plot(self._X_test[:,0], func(self._X_test)[:,0],\"-\", color = \"k\", label = \"true (test)\")\n",
    "            self.axs[1].plot(self._X_test[:,0], Y_pred_test[:,0],\".\", color = \"C0\", label = \"pred (test)\")\n",
    "            if Y_pred_test.shape[-1] >1:\n",
    "                m =  Y_pred_test[:,0]\n",
    "                s =  Y_pred_test[:,1]\n",
    "                self.axs[1].fill_between(self._X_test[:,0], m-1.414*s, m+1.414*s, color = \"C0\", alpha =.2)\n",
    "                \n",
    "            self.axs[1].plot(self._X_train[:,0], Y_pred_train[:,0],\".\", color = \"C1\", label = \"pred (train)\")\n",
    "\n",
    "            self.axs[1].set_ylim(-1.5,1.2)                                 \n",
    "            self.axs[1].legend()\n",
    "            self.axs[1].legend()\n",
    "\n",
    "            plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model(n_hidden = 2)\n",
    "model.compile(loss=\"mse\", optimizer=Adam(lr=0.005))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = MyCallback(X,Y, xlim_test = (-2,2), n_interval = 5)\n",
    "model.fit(X, Y, batch_size=2,\n",
    "          validation_data=(X_val, Y_val),\n",
    "          callbacks=[cb],\n",
    "          epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b = model.get_weights()[:2]\n",
    "print(w,b)\n",
    "plt.plot(X_val[:,0], model.predict(X_val)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tuple(w.mean() for w in cb._weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
